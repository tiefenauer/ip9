{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "from random import shuffle\n",
    "from lm.lm_util import process_sentence\n",
    "\n",
    "def load_lm(lm_path):\n",
    "    model = kenlm.LanguageModel(lm_path)\n",
    "    print(f'loaded {model.order}-gram model from {lm_path}')\n",
    "    return model\n",
    "\n",
    "def create_test_pair(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    sentence_original = ' '.join(words)\n",
    "    sentence_shuffled = sentence_original\n",
    "    while sentence_shuffled == sentence_original:\n",
    "        shuffle(words)\n",
    "        sentence_shuffled = ' '.join(words)\n",
    "    return sentence_original, sentence_shuffled\n",
    "\n",
    "def score_sentence(model, sentence):\n",
    "    print(f'score for \\'{sentence}\\': ', model.score(sentence))\n",
    "    for prob, ngram_length, oov in model.full_scores(sentence):\n",
    "        print({'probability': prob, \"n-gram lenght\": ngram_length, \"oov?\": oov})\n",
    "    print(\"perplexity:\", model.perplexity(sentence))\n",
    "    print()\n",
    "    \n",
    "def check_lm(model, sentences):\n",
    "    for sentence in sentences:\n",
    "        print('original sentence:', sentence)\n",
    "        sentence = process_sentence(sentence)\n",
    "        print('normalized sentence:', sentence)\n",
    "        original, shuffled = create_test_pair(sentence)\n",
    "        print()\n",
    "        print('scoring original sentence: ')\n",
    "        score_sentence(model, original)\n",
    "        print('scoring shuffled sentence: ')\n",
    "        score_sentence(model, shuffled)\n",
    "        \n",
    "english_sentences = [\n",
    "    'Language modelling is fun',\n",
    "    'New York'\n",
    "]\n",
    "german_sentences = [\n",
    "    'Seine Pressebeauftragte ist ratlos.',\n",
    "    'Fünf Minuten später steht er im Eingang des Kulturcafés an der Zürcher Europaallee.',\n",
    "    'Den Leuten wird bewusst, dass das System des Neoliberalismus nicht länger tragfähig ist.',\n",
    "    'Doch daneben gibt es die beeindruckende Zahl von 30\\'000 Bienenarten, die man unter dem Begriff «Wildbienen» zusammenfasst.',\n",
    "    'Bereits 1964 plante die US-Airline Pan American touristische Weltraumflüge für das Jahr 2000.',\n",
    "]\n",
    "german_sayings = [\n",
    "    'Ich bin ein Berliner',\n",
    "    'Man soll den Tag nicht vor dem Abend loben',\n",
    "    'Was ich nicht weiss macht mich nicht heiss',\n",
    "    'Ein Unglück kommt selten allein',\n",
    "    'New York'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-gram English LM\n",
    "\n",
    "The following model was trained on the TIMIT corpus and downloaded from the following location:\n",
    "\n",
    "https://www.dropbox.com/s/2n897gu5p3o2391/libri-timit-lm.kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('/home/daniel/KerasDeepSpeech/lm/libri-timit-lm.klm')\n",
    "check_lm(model, english_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Gram German LM\n",
    "The following is a 3-gram LM that has been trained with CMUSphinx. The ARPA file was downloaded from https://cmusphinx.github.io/wiki/download/ and converted to a binary KenLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/wiki_de/srilm-voxforge-de-r20171217.klm')\n",
    "check_lm(model, german_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-gram German LM (KenLM, probing)\n",
    "\n",
    "The following 2-gram model was trained on sentences from articles and pages in a Wikipedia dump. The dump was downloaded on 2018-09-21 and contains the state from 2018-09-01. The current dump of the German Wikipedia can be downloaded at http://download.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2.\n",
    "\n",
    "The model was not pruned. Probing was used as data structure. The following command was used to create the model:\n",
    "\n",
    "```bash\n",
    "lmplz -o 2 -T /home/daniel/tmp --skip_symbols -S 40% <../lm_data/wiki_de/wiki_de.txt.bz2 | build_binary /dev/stdin ../lm/wiki_de/wiki_de_2_gram.klm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/wiki_de/wiki_de_2_gram.klm')\n",
    "check_lm(model, german_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-gram German LM (KenLM, probing)\n",
    "\n",
    "The following 4-gram model was trained on the same dump like the 2-gram model above. Except for the order all other parameters were identical to the 2-gram model, i.e. in the bash command used for creating the model, all parameters except the `-o` parameters were the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/wiki_de/wiki_de_4_gram.klm')\n",
    "check_lm(model, german_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
