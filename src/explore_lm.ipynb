{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorint n-gram LM\n",
    "\n",
    "This Jupyter Notebook lets you explore some n-gram LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "from random import shuffle\n",
    "from lm.lm_util import process_sentence\n",
    "\n",
    "def load_lm(lm_path):\n",
    "    model = kenlm.LanguageModel(lm_path)\n",
    "    print(f'loaded {model.order}-gram model from {lm_path}')\n",
    "    return model\n",
    "\n",
    "def create_test_pair(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    sentence_original = ' '.join(words)\n",
    "    sentence_shuffled = sentence_original\n",
    "    while sentence_shuffled == sentence_original:\n",
    "        shuffle(words)\n",
    "        sentence_shuffled = ' '.join(words)\n",
    "    return sentence_original, sentence_shuffled\n",
    "\n",
    "def score_sentence(model, sentence):\n",
    "    score = model.score(sentence)\n",
    "    print(f'score for \\'{sentence}\\': ', score)\n",
    "    for prob, ngram_length, oov in model.full_scores(sentence):\n",
    "        print({'probability': prob, \"n-gram lenght\": ngram_length, \"oov?\": oov})\n",
    "    print(\"perplexity:\", model.perplexity(sentence))\n",
    "    print()\n",
    "    return score\n",
    "    \n",
    "def check_lm(model, sentences, language):\n",
    "    ok = True\n",
    "    for sentence in sentences:\n",
    "        print('original sentence:', sentence)\n",
    "        sentence = process_sentence(sentence, language=language)\n",
    "        print('normalized sentence:', sentence)\n",
    "        original, shuffled = create_test_pair(sentence)\n",
    "        print()\n",
    "        print('scoring original sentence: ')\n",
    "        score_original = score_sentence(model, original)\n",
    "        print('scoring shuffled sentence: ')\n",
    "        score_shuffled = score_sentence(model, shuffled)\n",
    "        if score_original < score_shuffled:\n",
    "            ok = False\n",
    "    if ok:\n",
    "        print('model seems to be OK')\n",
    "        \n",
    "english_sentences = [\n",
    "    'Language modeling is fun',\n",
    "    'New York'\n",
    "]\n",
    "german_sentences = [\n",
    "    'Seine Pressebeauftragte ist ratlos.',\n",
    "    'Fünf Minuten später steht er im Eingang des Kulturcafés an der Zürcher Europaallee.',\n",
    "    'Den Leuten wird bewusst, dass das System des Neoliberalismus nicht länger tragfähig ist.',\n",
    "    'Doch daneben gibt es die beeindruckende Zahl von 30\\'000 Bienenarten, die man unter dem Begriff «Wildbienen» zusammenfasst.',\n",
    "    'Bereits 1964 plante die US-Airline Pan American touristische Weltraumflüge für das Jahr 2000.',\n",
    "]\n",
    "german_sayings = [\n",
    "    'Ich bin ein Berliner',\n",
    "    'Man soll den Tag nicht vor dem Abend loben',\n",
    "    'Was ich nicht weiss macht mich nicht heiss',\n",
    "    'Ein Unglück kommt selten allein',\n",
    "    'New York'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model (4-gram, details unknown)\n",
    "\n",
    "The following model was trained on the TIMIT corpus and downloaded from https://www.dropbox.com/s/2n897gu5p3o2391/libri-timit-lm.kl. Details as the vocabulary or the data structure are not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/timit_en/libri-timit-lm.klm')\n",
    "check_lm(model, english_sentences, 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibriSpeech (4-gram)\n",
    "\n",
    "The following model has been trained on the LibriSpeech corpus. The ARPA file was downloaded from http://www.openslr.org/11. The ARPA model has been lowercased for the sake of consistence. Apart from that, no other preprocessing was done. The model was trained using a vocabulary of 200k words.\n",
    "\n",
    "A KenLM binary model was trained on the lowercased ARPA model using the _Trie_ data structure. This data structure is also what was used to train the German model (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/libri_en/librispeech-4-gram.klm')\n",
    "check_lm(model, english_sentences, 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRI model (3-Gram, CMUSphinx)\n",
    "The following is a 3-gram LM that has been trained with CMUSphinx. The ARPA file was downloaded from https://cmusphinx.github.io/wiki/download/ and converted to a binary KenLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/srilm_de/srilm-voxforge-de-r20171217.klm')\n",
    "check_lm(model, german_sentences, 'german')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom KenLM (2-gram, probing, all words)\n",
    "\n",
    "The following 2-gram model was trained on sentences from articles and pages in a Wikipedia dump. The dump was downloaded on 2018-09-21 and contains the state from 2018-09-01. The current dump of the German Wikipedia can be downloaded at http://download.wikimedia.org/dewiki/latest/dewiki-latest-pages-articles.xml.bz2.\n",
    "\n",
    "The model was not pruned. Probing was used as data structure. The following command was used to create the model:\n",
    "\n",
    "```bash\n",
    "lmplz -o 2 -T /home/daniel/tmp -S 40% <wiki_de.txt.bz2 | build_binary /dev/stdin wiki_de_2_gram.klm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/wiki_de/wiki_de_2_gram.klm')\n",
    "check_lm(model, german_sentences, 'german')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom KenLM (4-gram, trie, 500k words)\n",
    "\n",
    "The following 4-gram model was trained on the same dump like the 2-gram model above, but with a limited vocabulary of the first 500k most frequend words in the corpus. Additionally, a _Trie_ was used as data structure instead of the hash table in _Probing_. The model was built with the following program\n",
    "\n",
    "```bash\n",
    "lmplz -o 4 -T /home/daniel/tmp -S 40% <wiki_de.txt.bz2 | build_binary /dev/stdin wiki_de_4_gram_500k_trie.klm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_lm('../lm/wiki_de/wiki_de_4_gram_500k_trie.klm')\n",
    "check_lm(model, german_sentences, 'german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
