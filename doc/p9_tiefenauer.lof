\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of the simplified model. The cell type and the activation function is indicated in brackets for each layer (FC=Fully-Connected, ReLU=Rectified Linear Unit)\relax }}{7}{figure.caption.25}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2}{\ignorespaces Example of how the spell checker works\relax }}{10}{figure.caption.26}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3}{\ignorespaces Learning curve for the CTC-loss while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus using the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech}\relax }}{15}{figure.caption.32}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4}{\ignorespaces Learning curve for the \ac {LER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech} was used.\relax }}{16}{figure.caption.33}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5}{\ignorespaces Learning curve for the \ac {WER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech} was used.\relax }}{16}{figure.caption.34}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {6}{\ignorespaces Example of how Precision ($P$) and Recall ($R$) are calculated for alignments produced by the pipeline using the reference model and the alignments produced by pipeline using the simplified model.\relax }}{20}{figure.caption.38}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {7}{\ignorespaces Example of how the similarity between the alignment produced by the pipeline using the simplified model was compared and the alignment produced by the pipeline using the reference model (\textit {DeepSpeech}) for the alignments from figure \ref {precision_recall_fscore}\relax }}{20}{figure.caption.39}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {8}{\ignorespaces Average values of $P$, $R$ and $F$ for a pipeline using the simplified \ac {STT} model compared to a pipeline using a state of the art model. The box represents the range where 50\% of the data points are (\ac {IQR}). The whiskers extend to the last datum less than resp. more than $1.5 \cdot IQR$. Data beyond the whiskers are outliers (marked as circles). The \textit {DeepSpeech} model produces very accurate transcriptions and therefore very precise alignments ($P$ mean: $0.865$, median: $0.879$) and also a very high $F$-Score (mean: $0.926$, median: $0.935$). On the other hand, the simplified model produces only low-quality transcriptions, resulting in a lower Precision (mean: $0.435$, median: $0.443$). The $F$-Score is thus also lower (mean: $0.602$, median: $0.614$). Recall is very high for both pipeline variants.\relax }}{21}{figure.caption.40}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {9}{\ignorespaces average \ac {LER} between transcript and alignment (left plot) and similarity between alignments produced by a pipeline using the pre-trained \textit {DeepSpeech} model resp. the simplified model (right plot). The average \ac {LER} values when using the simplified model (mean: $0.982$, median: $0.800$) follow the same pattern like when using the reference model (mean: $0.230$, median: $0.148$), but are generally higher due to the lower quality of the transcriptions. However, this does not seem to affect the alignments produced by the two pipelines. The average similarity between alignments produced by the pipeline using the simplified model are roughly the same like when using the reference model (mean: $0.887$, median: $0.909$).\relax }}{22}{figure.caption.43}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {10}{\ignorespaces Word predictions of the trained 5-gram model for continuations of the stump \foreignquote *{french}{\textit {Ein 2007 erschienenes ...}}. The blue path represents a grammatically valid German sentence.\relax }}{30}{figure.caption.49}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {11}{\ignorespaces Impact of regularization and/or synthetisation on the progress of average \ac {LER} values. Regularization alone (left) will lead to lower \ac {LER} rates. Synthesized training data (middle) will lead to a smoother curve and lower \ac {LER} rates. Both measures combined will also combine their effects, although the trend is less obvious.\relax }}{31}{figure.caption.50}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {12}{\ignorespaces Average values of $P$, $R$ and $F$ for German audio/transcripts aligned with a pipeline using the simplified \ac {STT}. Precision is slightly higher than for the English pipeline (mean: 0.470, median: 0.453). However, this might be due to the fact that the German test set was much smaller (number of samples, total audio length) and also less diverse. The F-Score is similar to the one for the English pipeline (mean: 0.637, median: 0.626)\relax }}{31}{figure.caption.51}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {13}{\ignorespaces Average \ac {LER} (left plot) and \textit {Levenshtein Similiarity} (right plot) between transcript and alignment. Obviously shorter samples lead to better alignments because the \ac {LER} rate of the shorter transcripts from the \textit {ReadyLingua} corpus are much lower than the rates of the longer \textit {PodClub} samples. Vice versa the \textit {Levenshtein Similarity} decreases for longer samples.\relax }}{32}{figure.caption.52}
