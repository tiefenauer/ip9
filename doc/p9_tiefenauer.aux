\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\AC@reset@newl@bel
\abx@aux@refcontext{nyt/global//global/global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\babel@aux{english}{}
\AC@undonewlabel{acro:LM}
\newlabel{acro:LM}{{}{2}{\contentsname \@mkboth {\MakeUppercase \contentsname }{\MakeUppercase \contentsname }}{section*.3}{}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\AC@undonewlabel{acro:STT}
\newlabel{acro:STT}{{}{3}{\contentsname \@mkboth {\MakeUppercase \contentsname }{\MakeUppercase \contentsname }}{section*.4}{}}
\acronymused{STT}
\AC@undonewlabel{acro:CTC}
\newlabel{acro:CTC}{{}{3}{\contentsname \@mkboth {\MakeUppercase \contentsname }{\MakeUppercase \contentsname }}{section*.5}{}}
\acronymused{CTC}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{intro}{{1}{1}{Introduction}{section.1}{}}
\AC@undonewlabel{acro:FHNW}
\newlabel{acro:FHNW}{{1}{1}{Introduction}{section*.6}{}}
\acronymused{FHNW}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Scope and overall goal}{1}{subsection.1.1}}
\AC@undonewlabel{acro:RL}
\newlabel{acro:RL}{{1.1}{1}{Scope and overall goal}{section*.7}{}}
\acronymused{RL}
\AC@undonewlabel{acro:FA}
\newlabel{acro:FA}{{1.1}{1}{Scope and overall goal}{section*.8}{}}
\acronymused{FA}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Chosen approach and previous work}{1}{subsection.1.2}}
\AC@undonewlabel{acro:VAD}
\newlabel{acro:VAD}{{1.2}{1}{Chosen approach and previous work}{section*.9}{}}
\acronymused{VAD}
\AC@undonewlabel{acro:ASR}
\newlabel{acro:ASR}{{1.2}{1}{Chosen approach and previous work}{section*.10}{}}
\acronymused{ASR}
\AC@undonewlabel{acro:RNN}
\newlabel{acro:RNN}{{1.2}{1}{Chosen approach and previous work}{section*.11}{}}
\acronymused{RNN}
\AC@undonewlabel{acro:SA}
\newlabel{acro:SA}{{1.2}{1}{Chosen approach and previous work}{section*.12}{}}
\acronymused{SA}
\acronymused{VAD}
\acronymused{ASR}
\acronymused{SA}
\acronymused{ASR}
\acronymused{SA}
\acronymused{ASR}
\acronymused{ASR}
\abx@aux@cite{ctc_paper}
\abx@aux@segm{0}{0}{ctc_paper}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Previous results and problems}{2}{subsubsection.1.2.1}}
\acronymused{VAD}
\acronymused{SA}
\AC@undonewlabel{acro:SW}
\newlabel{acro:SW}{{1.2.1}{2}{Previous results and problems}{section*.13}{}}
\acronymused{SW}
\acronymused{SA}
\AC@undonewlabel{acro:LSA}
\newlabel{acro:LSA}{{1.2.1}{2}{Previous results and problems}{section*.14}{}}
\acronymused{LSA}
\acronymused{ASR}
\acronymused{RNN}
\acronymused{LSA}
\acronymused{ASR}
\AC@undonewlabel{acro:GCS}
\newlabel{acro:GCS}{{1.2.1}{2}{Previous results and problems}{section*.15}{}}
\acronymused{GCS}
\acronymused{GCS}
\acronymused{ASR}
\acronymused{GCS}
\acronymused{STT}
\acronymused{ASR}
\acronymused{CTC}
\acronymused{RNN}
\acronymused{ASR}
\AC@undonewlabel{acro:MFCC}
\newlabel{acro:MFCC}{{1.2.1}{2}{Previous results and problems}{section*.16}{}}
\acronymused{MFCC}
\acronymused{MFCC}
\acronymused{RNN}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Goal of this project}{2}{subsection.1.3}}
\acronymused{VAD}
\acronymused{LSA}
\acronymused{ASR}
\acronymused{RNN}
\acronymused{RNN}
\acronymused{RNN}
\acronymused{RNN}
\acronymused{RNN}
\acronymused{FA}
\acronymused{ASR}
\acronymused{RNN}
\acronymused{LM}
\acronymused{STT}
\acronymused{LM}
\acronymused{LM}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Summary}{3}{subsection.1.4}}
\acronymused{ASR}
\acronymused{STT}
\abx@aux@cite{deepspeech}
\abx@aux@segm{0}{0}{deepspeech}
\abx@aux@segm{0}{0}{deepspeech}
\abx@aux@segm{0}{0}{ctc_paper}
\abx@aux@cite{mozillajourney}
\abx@aux@segm{0}{0}{mozillajourney}
\abx@aux@cite{budget}
\abx@aux@segm{0}{0}{budget}
\abx@aux@cite{wav2letter}
\abx@aux@segm{0}{0}{wav2letter}
\abx@aux@segm{0}{0}{budget}
\abx@aux@segm{0}{0}{budget}
\abx@aux@segm{0}{0}{budget}
\abx@aux@segm{0}{0}{budget}
\abx@aux@segm{0}{0}{budget}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Training a Neural Network for Speech Recognition}{4}{section.2}}
\newlabel{ds}{{2}{4}{Training a Neural Network for Speech Recognition}{section.2}{}}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\textit  {DeepSpeech}: A reference model}{4}{subsection.2.1}}
\AC@undonewlabel{acro:NN}
\newlabel{acro:NN}{{2.1}{4}{\textit {DeepSpeech}: A reference model}{section*.17}{}}
\acronymused{NN}
\acronymused{ASR}
\AC@undonewlabel{acro:E2E}
\newlabel{acro:E2E}{{2.1}{4}{\textit {DeepSpeech}: A reference model}{section*.18}{}}
\acronymused{E2E}
\acronymused{MFCC}
\acronymused{LM}
\AC@undonewlabel{acro:WER}
\newlabel{acro:WER}{{2.1}{4}{\textit {DeepSpeech}: A reference model}{section*.19}{}}
\acronymused{WER}
\AC@undonewlabel{acro:LER}
\newlabel{acro:LER}{{2.1}{4}{\textit {DeepSpeech}: A reference model}{section*.20}{}}
\acronymused{LER}
\acronymused{WER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Related research}{4}{subsection.2.2}}
\acronymused{STT}
\acronymused{RNN}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{2.2}{4}{Related research}{section*.21}{}}
\acronymused{CNN}
\acronymused{LM}
\acronymused{CTC}
\acronymused{ASR}
\abx@aux@segm{0}{0}{budget}
\acronymused{CNN}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Exploiting the \textit  {DeepSpeech} model}{5}{subsection.2.3}}
\acronymused{FA}
\acronymused{ASR}
\acronymused{WER}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}A simpler model}{5}{subsection.2.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Differences between the IP8- and the IP9-model}{5}{subsubsection.2.4.1}}
\AC@undonewlabel{acro:SGD}
\newlabel{acro:SGD}{{2.4.1}{5}{Differences between the IP8- and the IP9-model}{section*.22}{}}
\acronymused{SGD}
\AC@undonewlabel{acro:DS}
\newlabel{acro:DS}{{2.4.1}{5}{Differences between the IP8- and the IP9-model}{section*.23}{}}
\acronymused{DS}
\acronymused{SGD}
\acronymused{SGD}
\abx@aux@segm{0}{0}{ctc_paper}
\abx@aux@segm{0}{0}{ctc_paper}
\acronymused{MFCC}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Differences between the simplified and the reference model}{6}{subsubsection.2.4.2}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\AC@undonewlabel{acro:LSTM}
\newlabel{acro:LSTM}{{2.4.2}{6}{Differences between the simplified and the reference model}{section*.24}{}}
\acronymused{LSTM}
\acronymused{LSTM}
\acronymused{LSTM}
\acronymused{MFCC}
\acronymused{LSTM}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of the simplified model. The cell type and the activation function is indicated in brackets for each layer (FC=Fully-Connected, ReLU=Rectified Linear Unit)\relax }}{7}{figure.caption.25}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{model_architecture}{{1}{7}{Architecture of the simplified model. The cell type and the activation function is indicated in brackets for each layer (FC=Fully-Connected, ReLU=Rectified Linear Unit)\relax }{figure.caption.25}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Summary}{7}{subsection.2.5}}
\abx@aux@cite{slp3}
\abx@aux@segm{0}{0}{slp3}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Integrating a Language Model}{8}{section.3}}
\newlabel{lm}{{3}{8}{Integrating a Language Model}{section.3}{}}
\acronymused{LM}
\acronymused{ASR}
\acronymused{LM}
\acronymused{DS}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Measuring and improving the performance of a Speech-To-Text engine}{8}{subsection.3.1}}
\acronymused{CTC}
\acronymused{STT}
\acronymused{WER}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{WER}
\acronymused{WER}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Language Models in Speech Recognition}{8}{subsection.3.2}}
\acronymused{LM}
\acronymused{LM}
\acronymused{NN}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}A simple spell checker}{8}{subsection.3.3}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{CTC}
\abx@aux@segm{0}{0}{mozillajourney}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{CTC}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{CTC}
\acronymused{WER}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Reducing the vocabulary size}{9}{subsubsection.3.3.1}}
\acronymused{LM}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of how the spell checker works\relax }}{10}{figure.caption.26}}
\newlabel{spell-checker}{{2}{10}{Example of how the spell checker works\relax }{figure.caption.26}{}}
\acronymused{LER}
\acronymused{LER}
\acronymused{WER}
\acronymused{WER}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Example for how a Spell-Checker (SC) can help improve the quality of an inferred transcription by changing characters and words. Audio and ground truth were taken from the \textit  {ReadyLingua} corpus and the inference was made with the pre-trained \textit  {DeepSpeech} model.\relax }}{10}{table.caption.27}}
\newlabel{ler_wer_example}{{1}{10}{Example for how a Spell-Checker (SC) can help improve the quality of an inferred transcription by changing characters and words. Audio and ground truth were taken from the \textit {ReadyLingua} corpus and the inference was made with the pre-trained \textit {DeepSpeech} model.\relax }{table.caption.27}{}}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Further thoughts and considerations}{11}{subsection.3.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Summary}{11}{subsection.3.5}}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Plotting a learning curve}{12}{section.4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Previous corpora and their problems}{12}{subsection.4.1}}
\AC@undonewlabel{acro:LS}
\newlabel{acro:LS}{{4.1}{12}{Previous corpora and their problems}{section*.28}{}}
\acronymused{LS}
\acronymused{RL}
\acronymused{LS}
\acronymused{LS}
\acronymused{LS}
\acronymused{RL}
\acronymused{LS}
\acronymused{RL}
\acronymused{RL}
\acronymused{LS}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The \textit  {CommonVoice} Corpus}{12}{subsection.4.2}}
\AC@undonewlabel{acro:CV}
\newlabel{acro:CV}{{4.2}{12}{The \textit {CommonVoice} Corpus}{section*.29}{}}
\acronymused{CV}
\abx@aux@segm{0}{0}{ctc_paper}
\acronymused{LS}
\acronymused{CV}
\acronymused{LS}
\acronymused{RL}
\acronymused{LS}
\acronymused{RL}
\acronymused{RL}
\acronymused{CV}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Statistics about corpora that were available for training.\relax }}{13}{table.caption.30}}
\newlabel{corpora_stats}{{2}{13}{Statistics about corpora that were available for training.\relax }{table.caption.30}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Plotting the learning curve}{13}{subsection.4.3}}
\acronymused{ASR}
\acronymused{CV}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{WER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Decoder dimension}{13}{subsubsection.4.3.1}}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}\ac {LM} dimension}{14}{subsubsection.4.3.2}}
\acronymused{LM}
\acronymused{LER}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Example of a transcription whose \ac {LER} was increased when using a spell checker\relax }}{14}{table.caption.31}}
\acronymused{LER}
\newlabel{lm_bad_example}{{3}{14}{Example of a transcription whose \ac {LER} was increased when using a spell checker\relax }{table.caption.31}{}}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Results and interpretation}{14}{subsection.4.4}}
\acronymused{CTC}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Learning curve for the CTC-loss while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus using the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit  {DeepSpeech}\relax }}{15}{figure.caption.32}}
\acronymused{CV}
\acronymused{LM}
\newlabel{lc_loss_cv}{{3}{15}{Learning curve for the CTC-loss while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus using the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech}\relax }{figure.caption.32}{}}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\acronymused{WER}
\acronymused{LER}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Learning curve for the \ac {LER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit  {DeepSpeech} was used.\relax }}{16}{figure.caption.33}}
\acronymused{LER}
\acronymused{CV}
\acronymused{LM}
\acronymused{LM}
\newlabel{lc_ler_cv}{{4}{16}{Learning curve for the \ac {LER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech} was used.\relax }{figure.caption.33}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Learning curve for the \ac {WER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit  {DeepSpeech} was used.\relax }}{16}{figure.caption.34}}
\acronymused{WER}
\acronymused{CV}
\acronymused{LM}
\acronymused{LM}
\newlabel{lc_wer_cv}{{5}{16}{Learning curve for the \ac {WER} metric while training on 1/10/100/1000 minutes of transcribed audio from the \ac {CV} corpus with and without spelling correction with a \ac {LM}. For the lines where spelling was corrected, the $5$-gram \ac {LM} provided by the Mozilla implementation of \textit {DeepSpeech} was used.\relax }{figure.caption.34}{}}
\acronymused{LER}
\abx@aux@cite{batch_size_rnn}
\abx@aux@segm{0}{0}{batch_size_rnn}
\acronymused{LER}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Example of how the quality for inferred transcripts improves with additional training data. The \ac {LER} values were calculated against the ground truth \foreignquote {french}{\textit  {i've got to go to him}}\relax }}{17}{table.caption.35}}
\acronymused{LER}
\newlabel{training_progress}{{4}{17}{Example of how the quality for inferred transcripts improves with additional training data. The \ac {LER} values were calculated against the ground truth \foreignquote {french}{\textit {i've got to go to him}}\relax }{table.caption.35}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison of the simplified model with and without dropout regularization. The average \ac {LER} was calculated over all samples from the \ac {CV} test-set. The best value is highlighted.\relax }}{17}{table.caption.36}}
\acronymused{LER}
\acronymused{CV}
\newlabel{comparison_regularized_unregularized}{{5}{17}{Comparison of the simplified model with and without dropout regularization. The average \ac {LER} was calculated over all samples from the \ac {CV} test-set. The best value is highlighted.\relax }{table.caption.36}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Regularization}{17}{subsection.4.5}}
\acronymused{LER}
\acronymused{CV}
\acronymused{LER}
\acronymused{LER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Final thoughts and considerations}{17}{subsection.4.6}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Summary}{18}{subsubsection.4.6.1}}
\acronymused{CTC}
\acronymused{LER}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Measuring the performance of the pipeline}{19}{section.5}}
\newlabel{e2e}{{5}{19}{Measuring the performance of the pipeline}{section.5}{}}
\acronymused{ASR}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}The quality of alignments}{19}{subsection.5.1}}
\acronymused{SA}
\acronymused{SA}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Metrics to evaluate the quality of alignments\relax }}{19}{table.caption.37}}
\newlabel{LM_evaluation}{{6}{19}{Metrics to evaluate the quality of alignments\relax }{table.caption.37}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Test and results}{20}{subsection.5.2}}
\acronymused{ASR}
\acronymused{ASR}
\acronymused{LER}
\AC@undonewlabel{acro:GSA}
\newlabel{acro:GSA}{{5.2}{20}{Test and results}{section*.38}{}}
\acronymused{GSA}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average values of $P$, $R$ and $F$ for a pipeline using the simplified \ac {STT} model compared to a pipeline using a state of the art model\relax }}{21}{figure.caption.39}}
\acronymused{STT}
\newlabel{pipeline_boxplot_ls_en}{{6}{21}{Average values of $P$, $R$ and $F$ for a pipeline using the simplified \ac {STT} model compared to a pipeline using a state of the art model\relax }{figure.caption.39}{}}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Summary}{21}{subsection.5.3}}
\acronymused{STT}
\acronymused{GSA}
\abx@aux@segm{0}{0}{budget}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces average \ac {LER} between transcript and alignment (left plot) and similarity between alignments made by using the pre-trained \textit  {DeepSpeech} model and the simplified model (right plot). The average \ac {LER} values when using the simplified model (mean: $0.982$, median: $0.800$) follow the same pattern like when using the reference model (mean: $0.230$, median: $0.148$), but are generally higher due to the lower quality of the transcriptions. However, this does not seem to affect the alignments produced by the two pipelines. The average similarity between alignments produced by the pipeline using the simplified model are roughly the same like when using the reference model (mean: $0.887$, median: $0.909$).\relax }}{22}{figure.caption.40}}
\acronymused{LER}
\acronymused{LER}
\newlabel{pipeline_scatterplot_ls_en}{{7}{22}{average \ac {LER} between transcript and alignment (left plot) and similarity between alignments made by using the pre-trained \textit {DeepSpeech} model and the simplified model (right plot). The average \ac {LER} values when using the simplified model (mean: $0.982$, median: $0.800$) follow the same pattern like when using the reference model (mean: $0.230$, median: $0.148$), but are generally higher due to the lower quality of the transcriptions. However, this does not seem to affect the alignments produced by the two pipelines. The average similarity between alignments produced by the pipeline using the simplified model are roughly the same like when using the reference model (mean: $0.887$, median: $0.909$).\relax }{figure.caption.40}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Forced Alignment for other languages}{22}{section.6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Inferring German transcripts}{22}{subsection.6.1}}
\acronymused{ASR}
\acronymused{ASR}
\acronymused{CV}
\acronymused{CV}
\acronymused{ASR}
\acronymused{RNN}
\acronymused{ASR}
\AC@undonewlabel{acro:BAS}
\newlabel{acro:BAS}{{6.1}{23}{Inferring German transcripts}{section*.41}{}}
\acronymused{BAS}
\acronymused{ASR}
\acronymused{ASR}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Data augmentation}{23}{subsection.6.2}}
\acronymused{CV}
\acronymused{CV}
\abx@aux@cite{kenlm}
\abx@aux@segm{0}{0}{kenlm}
\abx@aux@cite{nltk}
\abx@aux@segm{0}{0}{nltk}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Comparison of \ac {RL} corpus before and after data augmentation (training set only)\relax }}{24}{table.caption.42}}
\acronymused{RL}
\newlabel{corpus_synth_stats}{{7}{24}{Comparison of \ac {RL} corpus before and after data augmentation (training set only)\relax }{table.caption.42}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Creating a Language Model for German}{24}{subsection.6.3}}
\acronymused{ASR}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Creating a raw text corpus}{24}{subsection.6.4}}
\AC@undonewlabel{acro:OOV}
\newlabel{acro:OOV}{{6.4}{24}{Creating a raw text corpus}{section*.43}{}}
\acronymused{OOV}
\abx@aux@cite{raj_lossless}
\abx@aux@segm{0}{0}{raj_lossless}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Representation in corpus}{25}{lstlisting.1}}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Training the \ac {LM}}{25}{subsection.6.5}}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.1}Data structures}{25}{subsubsection.6.5.1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.2}Quantization}{25}{subsubsection.6.5.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.3}Pointer Compression}{25}{subsubsection.6.5.3}}
\abx@aux@segm{0}{0}{slp3}
\abx@aux@segm{0}{0}{slp3}
\abx@aux@segm{0}{0}{kenlm}
\abx@aux@cite{kenlm_estimation}
\abx@aux@segm{0}{0}{kenlm_estimation}
\abx@aux@segm{0}{0}{kenlm_estimation}
\abx@aux@segm{0}{0}{kenlm_estimation}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.5.4}Building the model}{26}{subsubsection.6.5.4}}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Evaluating the \ac {LM}}{26}{subsection.6.6}}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.1}Extrinsic and intrinsic evaluation}{26}{subsubsection.6.6.1}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2}Evaluation of KenLM}{26}{subsubsection.6.6.2}}
\acronymused{LM}
\AC@undonewlabel{acro:SRILM}
\newlabel{acro:SRILM}{{6.6.2}{26}{Evaluation of KenLM}{section*.44}{}}
\acronymused{SRILM}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3}Evaluation of the German Wikipedia \ac {LM}}{26}{subsubsection.6.6.3}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.4}Evaluation 1: Comparing scores of randomized sentences}{27}{subsubsection.6.6.4}}
\acronymused{LM}
\@writefile{lol}{\defcounter {refsection}{0}\relax }\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Representation in corpus}{27}{lstlisting.2}}
\acronymused{LM}
\acronymused{LM}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.5}Experiment 2: Word predictor}{27}{subsubsection.6.6.5}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Comparison of log10-probabilities calculated for news sentences and a permutation of their words\relax }}{28}{table.caption.45}}
\newlabel{LM_evaluation}{{8}{28}{Comparison of log10-probabilities calculated for news sentences and a permutation of their words\relax }{table.caption.45}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Word predictions of the trained 5-gram model for continuations of the stump \foreignquote *{french}{\textit  {Ein 2007 erschienenes ...}}. The blue path represents a grammatically valid German sentence.\relax }}{28}{figure.caption.46}}
\newlabel{word_predictor}{{8}{28}{Word predictions of the trained 5-gram model for continuations of the stump \foreignquote *{french}{\textit {Ein 2007 erschienenes ...}}. The blue path represents a grammatically valid German sentence.\relax }{figure.caption.46}{}}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}\ac {STT} model performance}{28}{subsection.6.7}}
\acronymused{LER}
\acronymused{LER}
\acronymused{LS}
\acronymused{RL}
\acronymused{LS}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Impact of regularization and/or synthetisation on the progress of average \ac {LER} values. Regularization alone (left) will lead to lower \ac {LER} rates. Synthesized training data (middle) will lead to a smoother curve and lower \ac {LER} rates. Both measures combined will also combine their effects, although the trend is less obvious.\relax }}{29}{figure.caption.47}}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\newlabel{regularization_synthetisation}{{9}{29}{Impact of regularization and/or synthetisation on the progress of average \ac {LER} values. Regularization alone (left) will lead to lower \ac {LER} rates. Synthesized training data (middle) will lead to a smoother curve and lower \ac {LER} rates. Both measures combined will also combine their effects, although the trend is less obvious.\relax }{figure.caption.47}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Pipeline performance}{29}{subsection.6.8}}
\acronymused{LER}
\acronymused{ASR}
\acronymused{ASR}
\acronymused{GSA}
\acronymused{VAD}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.9}Summary}{29}{subsection.6.9}}
\acronymused{LM}
\acronymused{STT}
\acronymused{STT}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{31}{section.7}}
\newlabel{conclusion}{{7}{31}{Conclusion}{section.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Outlook and further work}{31}{subsection.7.1}}
\acronymused{CV}
\acronymused{LM}
\acronymused{LER}
\acronymused{CV}
\acronymused{LM}
\acronymused{LM}
\acronymused{WER}
\acronymused{CV}
\acronymused{LM}
\acronymused{LM}
\acronymused{STT}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{LER}
\acronymused{CV}
\acronymused{RL}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Appendix}{33}{section.8}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Acronyms used in this document}{33}{subsection.8.1}}
\newlabel{acronyms}{{8.1}{33}{Acronyms used in this document}{subsection.8.1}{}}
\newacro{ASR}[\AC@hyperlink{ASR}{ASR}]{Automatic Speech Recognition}
\newacro{BAS}[\AC@hyperlink{BAS}{BAS}]{Bavarian Archive for Speech Signals}
\newacro{CNN}[\AC@hyperlink{CNN}{CNN}]{Convolutional Neural Network}
\newacro{CTC}[\AC@hyperlink{CTC}{CTC}]{Connectionist Temporal Classification}
\newacro{CV}[\AC@hyperlink{CV}{CV}]{CommonVoice}
\newacro{DS}[\AC@hyperlink{DS}{DS}]{Deep Speech}
\newacro{E2E}[\AC@hyperlink{E2E}{E2E}]{end-to-end}
\newacro{FA}[\AC@hyperlink{FA}{FA}]{Forced Alignment}
\newacro{FHNW}[\AC@hyperlink{FHNW}{FHNW}]{University of Applied Sciences}
\newacro{GCS}[\AC@hyperlink{GCS}{GCS}]{Google Cloud Speech}
\newacro{GPU}[\AC@hyperlink{GPU}{GPU}]{Graphics Processing Unit}
\newacro{GRU}[\AC@hyperlink{GRU}{GRU}]{Gated Recurrent Unit}
\newacro{GSA}[\AC@hyperlink{GSA}{GSA}]{Global Sequence Alignment}
\newacro{LER}[\AC@hyperlink{LER}{LER}]{Label Error Rate}
\newacro{LM}[\AC@hyperlink{LM}{LM}]{Language Model}
\newacro{LS}[\AC@hyperlink{LS}{LS}]{LibriSpeech}
\newacro{LSTM}[\AC@hyperlink{LSTM}{LSTM}]{Long Short Term Memory}
\newacro{LSA}[\AC@hyperlink{LSA}{LSA}]{Local Sequence Alignment}
\newacro{MFCC}[\AC@hyperlink{MFCC}{MFCC}]{Mel-Frequency Cepstral Coefficients}
\newacro{NN}[\AC@hyperlink{NN}{NN}]{Neural Network}
\newacro{RL}[\AC@hyperlink{RL}{RL}]{ReadyLingua}
\newacro{RNN}[\AC@hyperlink{RNN}{RNN}]{Recurrent Neural Network}
\newacro{SA}[\AC@hyperlink{SA}{SA}]{Sequence Alignment}
\newacro{SGD}[\AC@hyperlink{SGD}{SGD}]{Stochastic Gradient Descent}
\newacro{STT}[\AC@hyperlink{STT}{STT}]{Speech-To-Text}
\newacro{OOV}[\AC@hyperlink{OOV}{OOV}]{Out Of Vocabulary}
\newacro{SRILM}[\AC@hyperlink{SRILM}{SRILM}]{the SRI Language Modelling Toolkit}
\newacro{SW}[\AC@hyperlink{SW}{SW}]{Smith Waterman}
\newacro{VAD}[\AC@hyperlink{VAD}{VAD}]{Voice Activity Detection}
\newacro{WER}[\AC@hyperlink{WER}{WER}]{Word Error Rate}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}The simple spell checker in detail}{34}{subsection.8.2}}
\newlabel{spellchecker}{{8.2}{34}{The simple spell checker in detail}{subsection.8.2}{}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{CTC}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}How \ac {CTC} works}{34}{subsection.8.3}}
\newlabel{ctc-summary}{{8.3}{34}{How \ac {CTC} works}{subsection.8.3}{}}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{CTC}
\acronymused{ASR}
\acronymused{CTC}
\acronymused{CTC}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}n-Gram Language Models}{35}{subsection.8.4}}
\newlabel{n-gram-summary}{{8.4}{35}{n-Gram Language Models}{subsection.8.4}{}}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{LM}
\acronymused{OOV}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.1}Perplexity, discount and smoothing}{35}{subsubsection.8.4.1}}
\acronymused{LM}
\acronymused{LM}
\acronymused{OOV}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.2}Kneser-Ney Smoothing}{35}{subsubsection.8.4.2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {9}Author's declaration}{37}{section.9}}
\newlabel{LastPage}{{}{37}{}{page.37}{}}
\xdef\lastpage@lastpage{37}
\xdef\lastpage@lastpageHy{37}
