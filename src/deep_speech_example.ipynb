{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSpeech\n",
    "\n",
    "The following scripts require you to [download the pre-trained model from DeepSpeech](https://github.com/mozilla/DeepSpeech#getting-the-pre-trained-model) and store the downloaded files somewhere. Make sure the model was trained with the same version as your `deepspeech` module. Type `pip show deepspeech` to see what Python module version you have installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these parameters to load a different model\n",
    "model_path = \"/media/daniel/IP9/asr/output_graph.pb\"\n",
    "alphabet_path = \"/media/daniel/IP9/asr/alphabet.txt\"\n",
    "lm_path = \"/media/daniel/IP9/asr/lm.binary\"\n",
    "trie_path = \"/media/daniel/IP9/asr/trie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to load the model. The model is loaded twice, once with and once without a Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These constants control the beam search decoder\n",
    "BEAM_WIDTH = 500  # Beam width used in the CTC decoder when building candidate transcriptions\n",
    "LM_WEIGHT = 1.75  # The alpha hyperparameter of the CTC decoder. Language Model weight\n",
    "# Valid word insertion weight. This is used to lessen the word insertion penalty\n",
    "# when the inserted word is part of the vocabulary\n",
    "VALID_WORD_COUNT_WEIGHT = 1.00\n",
    "# These constants are tied to the shape of the graph used (changing them changes\n",
    "# the geometry of the first layer), so make sure you use the same constants that\n",
    "# were used during training\n",
    "# Number of MFCC features to use\n",
    "N_FEATURES = 26\n",
    "# Size of the context window used for producing timesteps in the input vector\n",
    "N_CONTEXT = 9\n",
    "\n",
    "from deepspeech import Model\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def load_model(model_path, alphabet_path, lm_path=None, trie_path=None):\n",
    "    # load pre-trained DeepSpeech model from file\n",
    "    print(f'Loading model with{\"out\" if lm_path else \"\"} LM from file {model_path}', file=sys.stderr)\n",
    "    model_load_start = timer()\n",
    "    ds = Model(model_path, N_FEATURES, N_CONTEXT, alphabet_path, BEAM_WIDTH)\n",
    "    model_load_end = timer() - model_load_start\n",
    "    \n",
    "    if lm_path and trie_path:\n",
    "        print(f'Loading language model from files {lm_path} {trie_path}', file=sys.stderr)\n",
    "        lm_load_start = timer()\n",
    "        ds.enableDecoderWithLM(alphabet_path, lm_path, trie_path, LM_WEIGHT, VALID_WORD_COUNT_WEIGHT)\n",
    "        lm_load_end = timer() - lm_load_start\n",
    "        print(f'Loaded language model in {lm_load_end:.3}s.', file=sys.stderr)\n",
    "    print(f'Loaded model in {model_load_end:.3}s.', file=sys.stderr)    \n",
    "    return ds\n",
    "    \n",
    "model_without_lm = load_model(model_path, alphabet_path)\n",
    "model_with_lm = load_model(model_path, alphabet_path, lm_path, trie_path)\n",
    "print('Done!')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring from corpus segments\n",
    "\n",
    "The following code can be used to run inference on random samples from the _ReadyLingua_ corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "from util.corpus_util import *\n",
    "\n",
    "corpus_path = '/media/daniel/IP9/corpora/readylingua'\n",
    "corpus = get_corpus(corpus_path)(languages='en')\n",
    "corpus.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio, display\n",
    "from pattern3.metrics import levenshtein_similarity\n",
    "import random\n",
    "\n",
    "def get_random_test_samples(corpus, num=5):\n",
    "    print(f'selecting {num} random speech segments from testset (corpus: {corpus.name})')    \n",
    "    test_segments = corpus.test_set()\n",
    "    return random.sample(test_segments, num)\n",
    "\n",
    "segments = get_random_test_samples(corpus)\n",
    "\n",
    "for i, segment in enumerate(segments):\n",
    "    print(f'Inferring transcription for speech segment #{i}')\n",
    "    audio, rate = segment.audio, segment.rate\n",
    "    transcription_noLM = model_without_lm.stt(audio, rate)\n",
    "    transcription_LM = model_with_lm.stt(audio, rate)\n",
    "    \n",
    "    display(HTML(f'<strong>From corpus entry</strong>: {segment.entry.id}'))\n",
    "    display(Audio(data=audio, rate=rate))\n",
    "    display(HTML(f'<strong>actual transcription</strong>:<br/>{segment.transcript}'))    \n",
    "    display(HTML(f'<strong>inferred transcription (without LM)</strong>:<br/>{transcription_noLM}'))    \n",
    "    display(HTML(f'<strong>Levenshtein similarity (=LER)</strong>: {levenshtein_similarity(transcription_noLM, segment.transcript)}'))\n",
    "    display(HTML(f'<strong>inferred transcription (with LM)</strong>:<br/>{transcription_LM}'))        \n",
    "    display(HTML(f'<strong>Levenshtein similarity (=LER)</strong>: {levenshtein_similarity(transcription_LM, segment.transcript)}'))\n",
    "    \n",
    "    display(HTML(f'<hr/>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
