{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these parameters to load a different model\n",
    "model_path = \"/home/daniel/models/output_graph.pb\"\n",
    "alphabet_path = \"/home/daniel/models/alphabet.txt\"\n",
    "lm_path = \"/home/daniel/models/lm.binary\"\n",
    "trie_path = \"/home/daniel/models/trie\"\n",
    "\n",
    "# These constants control the beam search decoder\n",
    "BEAM_WIDTH = 500  # Beam width used in the CTC decoder when building candidate transcriptions\n",
    "LM_WEIGHT = 1.75  # The alpha hyperparameter of the CTC decoder. Language Model weight\n",
    "# Valid word insertion weight. This is used to lessen the word insertion penalty\n",
    "# when the inserted word is part of the vocabulary\n",
    "VALID_WORD_COUNT_WEIGHT = 1.00\n",
    "# These constants are tied to the shape of the graph used (changing them changes\n",
    "# the geometry of the first layer), so make sure you use the same constants that\n",
    "# were used during training\n",
    "# Number of MFCC features to use\n",
    "N_FEATURES = 26\n",
    "# Size of the context window used for producing timesteps in the input vector\n",
    "N_CONTEXT = 9\n",
    "\n",
    "from deepspeech.model import Model\n",
    "import sys\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def load_model(model_path, alphabet_path, lm_path=None, trie_path=None):\n",
    "    # load pre-trained DeepSpeech model from file\n",
    "    print(f'Loading model with{\"out\" if lm_path else \"\"} LM from file {model_path}', file=sys.stderr)\n",
    "    model_load_start = timer()\n",
    "    ds = Model(model_path, N_FEATURES, N_CONTEXT, alphabet_path, BEAM_WIDTH)\n",
    "    model_load_end = timer() - model_load_start\n",
    "    \n",
    "    if lm_path and trie_path:\n",
    "        print(f'Loading language model from files {lm_path} {trie_path}', file=sys.stderr)\n",
    "        lm_load_start = timer()\n",
    "        ds.enableDecoderWithLM(alphabet_path, lm_path, trie_path, LM_WEIGHT, VALID_WORD_COUNT_WEIGHT, VALID_WORD_COUNT_WEIGHT)\n",
    "        lm_load_end = timer() - lm_load_start\n",
    "        print(f'Loaded language model in {lm_load_end:.3}s.', file=sys.stderr)\n",
    "    print(f'Loaded model in {model_load_end:.3}s.', file=sys.stderr)    \n",
    "    return ds\n",
    "    \n",
    "model_without_lm = load_model(model_path, alphabet_path)\n",
    "model_with_lm = load_model(model_path, alphabet_path, lm_path, trie_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "from util.corpus_util import *\n",
    "\n",
    "corpus = get_corpus('rl')(languages='en')\n",
    "# corpus = get_corpus('ls')\n",
    "corpus.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio, display\n",
    "from pattern3.metrics import levenshtein_similarity\n",
    "import random\n",
    "\n",
    "def get_random_test_samples(corpus, num=5):\n",
    "    print(f'selecting {num} random speech segments from testset (corpus: {corpus.name})')    \n",
    "    _,_,test_segments = corpus.train_dev_test_split(include_numeric=True)\n",
    "    return random.sample(test_segments, num)\n",
    "\n",
    "segments = get_random_test_samples(corpus)\n",
    "\n",
    "for i, segment in enumerate(segments):\n",
    "    print(f'Inferring transcription for speech segment #{i}')\n",
    "    audio, rate = segment.audio, segment.rate\n",
    "    transcription_noLM = model_without_lm.stt(audio, rate)\n",
    "    transcription_LM = model_with_lm.stt(audio, rate)\n",
    "    \n",
    "    display(HTML(f'<strong>From corpus entry</strong>: {segment.corpus_entry.name} ({segment.corpus_entry.id})'))    \n",
    "    display(Audio(data=audio, rate=rate))\n",
    "    display(HTML(f'<strong>actual transcription</strong>:<br/>{segment.text}'))    \n",
    "    display(HTML(f'<strong>inferred transcription (without LM)</strong>:<br/>{transcription_noLM}'))    \n",
    "    display(HTML(f'<strong>Levenshtein similarity (=LER)</strong>: {levenshtein_similarity(transcription_noLM, segment.text)}'))\n",
    "    display(HTML(f'<strong>inferred transcription (with LM)</strong>:<br/>{transcription_LM}'))        \n",
    "    display(HTML(f'<strong>Levenshtein similarity (=LER)</strong>: {levenshtein_similarity(transcription_LM, segment.text)}'))\n",
    "    \n",
    "    display(HTML(f'<hr/>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
